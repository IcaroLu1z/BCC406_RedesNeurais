{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/IcaroLu1z/BCC406_RedesNeurais/blob/main/TrabalhoPratico_ModelosClassicos.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "s11zLiqZxZzK"
      },
      "source": [
        "# ***Dependencias***"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vCSkKmc9xZEj"
      },
      "outputs": [],
      "source": [
        "# Bibliotecas processamento\n",
        "import sklearn as sk\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "# Bibliotecas aprendizado\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "\n",
        "# Bibliotecas validacao\n",
        "from sklearn import metrics\n",
        "from sklearn.model_selection import cross_validate\n",
        "from sklearn.model_selection import cross_val_score\n",
        "\n",
        "from sklearn.model_selection import StratifiedKFold\n",
        "\n",
        "#Biblioteca seaborn\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "from sklearn.metrics import accuracy_score\n",
        "from sklearn.metrics import classification_report, confusion_matrix\n",
        "from sklearn import tree\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "sns.set(font_scale=1.2)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nGZWiMtjbZBw"
      },
      "source": [
        "#***Pré-Processamento***"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 380
        },
        "id": "xxqtduB5yddZ",
        "outputId": "32f18092-73af-463d-b7c8-ab4740551105"
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "FileNotFoundError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-2-63a4bef6ccc1>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# Importar conjunto de dados\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mdf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'/content/sample_data/German_Credit_dataset.csv'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdelimiter\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\",\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minfo\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhead\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pandas/util/_decorators.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    309\u001b[0m                     \u001b[0mstacklevel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mstacklevel\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    310\u001b[0m                 )\n\u001b[0;32m--> 311\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    312\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    313\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36mread_csv\u001b[0;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, squeeze, prefix, mangle_dupe_cols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, error_bad_lines, warn_bad_lines, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options)\u001b[0m\n\u001b[1;32m    584\u001b[0m     \u001b[0mkwds\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkwds_defaults\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    585\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 586\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0m_read\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    587\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    588\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36m_read\u001b[0;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[1;32m    480\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    481\u001b[0m     \u001b[0;31m# Create the parser.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 482\u001b[0;31m     \u001b[0mparser\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTextFileReader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    483\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    484\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mchunksize\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0miterator\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[1;32m    809\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"has_index_names\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"has_index_names\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    810\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 811\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_make_engine\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mengine\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    812\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    813\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36m_make_engine\u001b[0;34m(self, engine)\u001b[0m\n\u001b[1;32m   1038\u001b[0m             )\n\u001b[1;32m   1039\u001b[0m         \u001b[0;31m# error: Too many arguments for \"ParserBase\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1040\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mmapping\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mengine\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[call-arg]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1041\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1042\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_failover_to_python\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pandas/io/parsers/c_parser_wrapper.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, src, **kwds)\u001b[0m\n\u001b[1;32m     49\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     50\u001b[0m         \u001b[0;31m# open handles\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 51\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_open_handles\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msrc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     52\u001b[0m         \u001b[0;32massert\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhandles\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     53\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pandas/io/parsers/base_parser.py\u001b[0m in \u001b[0;36m_open_handles\u001b[0;34m(self, src, kwds)\u001b[0m\n\u001b[1;32m    227\u001b[0m             \u001b[0mmemory_map\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"memory_map\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    228\u001b[0m             \u001b[0mstorage_options\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"storage_options\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 229\u001b[0;31m             \u001b[0merrors\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"encoding_errors\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"strict\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    230\u001b[0m         )\n\u001b[1;32m    231\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pandas/io/common.py\u001b[0m in \u001b[0;36mget_handle\u001b[0;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[1;32m    705\u001b[0m                 \u001b[0mencoding\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mioargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mencoding\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    706\u001b[0m                 \u001b[0merrors\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0merrors\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 707\u001b[0;31m                 \u001b[0mnewline\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    708\u001b[0m             )\n\u001b[1;32m    709\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '/content/sample_data/German_Credit_dataset.csv'"
          ]
        }
      ],
      "source": [
        "# Importar conjunto de dados\n",
        "df = pd.read_csv('/content/sample_data/German_Credit_dataset.csv', delimiter=\",\")\n",
        "\n",
        "df.info()\n",
        "df.head()\n",
        "\n",
        "ax = plt.subplot()\n",
        "plt.figure()\n",
        "\n",
        "sns.countplot(\"'class'\", data=df, ax=ax)\n",
        "ax.set_xlabel('Classe');ax.set_ylabel('Instancias'); \n",
        "ax.xaxis.set_ticklabels(['Bom', 'Ruim']);\n",
        "df.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vvzClnYkzKsp"
      },
      "outputs": [],
      "source": [
        "def formatColunm(col):\n",
        "  le = sk.preprocessing.LabelEncoder()\n",
        "  le.fit(df[col])\n",
        "  df[col] = le.transform(df[col])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dCMIss1F4Xue"
      },
      "outputs": [],
      "source": [
        "formatColunm(\"'checking_status'\")\n",
        "formatColunm(\"'credit_history'\")\n",
        "formatColunm(\"'purpose'\")\n",
        "formatColunm(\"'savings_status'\")\n",
        "formatColunm(\"'employment'\")\n",
        "formatColunm(\"'personal_status'\")\n",
        "formatColunm(\"'other_parties'\")\n",
        "formatColunm(\"'property_magnitude'\")\n",
        "formatColunm(\"'other_payment_plans'\")\n",
        "formatColunm(\"'housing'\")\n",
        "formatColunm(\"'job'\")\n",
        "formatColunm(\"'own_telephone'\")\n",
        "formatColunm(\"'foreign_worker'\")\n",
        "formatColunm(\"'class'\")\n",
        "\n",
        "df.info()\n",
        "df.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YwVV09eE5jYK"
      },
      "outputs": [],
      "source": [
        "#df.drop(\"id\", axis = 1, inplace = True)\n",
        "\n",
        "#df.drop([\"'age'\"], axis = 1, inplace = True)\n",
        "\n",
        "df.info()\n",
        "df.head()"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "X = df.values[:,:-1] \n",
        "y = df.values[:,-1]\n"
      ],
      "metadata": {
        "id": "S1OtXUZc9jFw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from collections import Counter\n",
        "from sklearn.datasets import make_classification\n",
        "from imblearn.over_sampling import SMOTE\n",
        "from matplotlib import pyplot\n",
        "from numpy import where\n",
        "# define dataset\n",
        "# summarize class distribution\n",
        "counter = Counter(y)\n",
        "print(counter)\n",
        "# transform the dataset\n",
        "oversample = SMOTE()\n",
        "X, y = oversample.fit_resample(X, y)\n",
        "# summarize the new class distribution\n",
        "counter = Counter(y)\n",
        "print(counter)\n",
        "# scatter plot of examples by class label\n",
        "for label, _ in counter.items():\n",
        "\trow_ix = where(y == label)[0]\n",
        "\tpyplot.scatter(X[row_ix, 0], X[row_ix, 1], label=str(label))\n",
        "pyplot.legend()\n",
        "pyplot.show()"
      ],
      "metadata": {
        "id": "CQx4cCsezz24"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "c = np.c_[X, y]\n",
        "\n",
        "clean_df = pd.DataFrame(c, index=None)\n",
        "\n",
        "clean_df.info()\n",
        "clean_df.head()\n",
        "\n",
        "#clean_df.to_csv(r'German_Credit_dataset_balanced.csv')\n",
        "\n",
        "clean_df.nunique(axis=0)\n",
        "\n",
        "ax = plt.subplot()\n",
        "plt.figure()\n",
        "\n",
        "sns.countplot(21, data=clean_df, ax=ax)\n",
        "ax.xaxis.set_ticklabels(['Bom', 'Ruim']);\n",
        "\n",
        "ax.set_xlabel('Classe');ax.set_ylabel('Instancias'); \n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "WxWrNGVz6IRe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nyc1OBuZ6LOA"
      },
      "outputs": [],
      "source": [
        "data = clean_df[21].value_counts()\n",
        "\n",
        "colors = sns.color_palette('pastel')[0:5]\n",
        "plt.pie(data, labels=[\"Good\", \"Bad\"], colors = colors, autopct='%.0f%%')\n",
        "plt.show"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "shuffled_df = df.sample(frac=1,random_state=4)\n",
        "\n",
        "# Put all the fraud class in a separate dataset.\n",
        "bad_df = shuffled_df.loc[df[\"'class'\"] == 0]\n",
        "\n",
        "#Randomly select 492 observations from the non-fraud (majority class)\n",
        "good_df = shuffled_df.loc[df[\"'class'\"] == 1].sample(n=300,random_state=42)\n",
        "\n",
        "# Concatenate both dataframes again\n",
        "normalized_df = pd.concat([good_df, bad_df])\n",
        "\n",
        "#plot the dataset after the undersampling\n",
        "plt.figure(figsize=(8, 8))\n",
        "sns.countplot(\"'class'\", data=normalized_df)\n",
        "plt.title('Balanced Classes')\n",
        "plt.show()\n",
        "\n",
        "dfO_train, dfO_test = train_test_split(normalized_df, test_size=0.3)"
      ],
      "metadata": {
        "id": "c9KTYLZGyJeL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ycMXIxdyb64j"
      },
      "source": [
        "#***Predição do DataFrame Original - 700 Goods e 300 Bads***"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uoWL9cXoB5qh"
      },
      "outputs": [],
      "source": [
        "df = df.sample(frac=1, random_state= 1).reset_index(drop=True)\n",
        "\n",
        "X = df.values[:,:-1] \n",
        "Y = df.values[:,-1]\n",
        "testTrain = 0.3\n",
        "\n",
        "X_train, X_test, Y_train, Y_test = sk.model_selection.train_test_split(X, Y, test_size = testTrain)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "d7Aio8DUHQ3s"
      },
      "outputs": [],
      "source": [
        "modelo1 = LogisticRegression(max_iter=1000)\n",
        "modelo1.fit(X_train, Y_train)\n",
        "\n",
        "modelo2 = DecisionTreeClassifier()\n",
        "modelo2.fit(X_train, Y_train)\n",
        "\n",
        "modelo3 = RandomForestClassifier()\n",
        "modelo3.fit(X_train, Y_train)\n",
        "\n",
        "Modelo1 = modelo1.predict(X_test)\n",
        "Modelo2 = modelo2.predict(X_test)\n",
        "Modelo3 = modelo3.predict(X_test)\n",
        "\n",
        "print('Logistic REgression')\n",
        "print(classification_report(Y_test, Modelo1))\n",
        "print(classification_report(Y_test, Modelo2))\n",
        "print(classification_report(Y_test, Modelo3))\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "y1pOl3KhcKUH"
      },
      "source": [
        "#***Predição do DataFrame Equlibrado - 700 Goods e 700 Bads***"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MnsAmDftSkGX"
      },
      "outputs": [],
      "source": [
        "Xc = clean_df.values[:,:-1] \n",
        "Yc = clean_df.values[:,-1]\n",
        "\n",
        "Xd = normalized_df.values[:,:-1] \n",
        "Yd = normalized_df.values[:,-1]\n",
        "\n",
        "Xc_train, Xc_test, Yc_train, Yc_test = sk.model_selection.train_test_split(Xc, Yc, test_size = testTrain)\n",
        "\n",
        "Xd_train, Xd_test, Yd_train, Yd_test= train_test_split(Xd, Yd, test_size = 0.4) "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gRvreD6zTtbr"
      },
      "outputs": [],
      "source": [
        "modelo4 = LogisticRegression(max_iter=2000)\n",
        "modelo4.fit(Xc_train, Yc_train)\n",
        "\n",
        "modelo5 = DecisionTreeClassifier()\n",
        "modelo5.fit(Xc_train, Yc_train)\n",
        "\n",
        "modelo6 = RandomForestClassifier()\n",
        "modelo6.fit(Xc_train, Yc_train)\n",
        "\n",
        "Modelo4 = modelo4.predict(Xd_test)\n",
        "Modelo5 = modelo5.predict(Xd_test)\n",
        "Modelo6 = modelo6.predict(Xd_test)\n",
        "\n",
        "print(classification_report(Yd_test, Modelo4))\n",
        "print(classification_report(Yd_test, Modelo5))\n",
        "print(classification_report(Yd_test, Modelo6))\n",
        "\n",
        "ax = plt.subplot()\n",
        "plt.figure()\n",
        "sns.heatmap(confusion_matrix(Yd_test, Modelo4), annot=True, fmt=\".0f\", ax=ax)\n",
        "\n",
        "ax.set_xlabel('Predicted labels');ax.set_ylabel('True labels'); \n",
        "ax.set_title('Regressão Logistica'); \n",
        "ax.xaxis.set_ticklabels(['Bom', 'Ruim']); ax.yaxis.set_ticklabels(['Bom', 'Ruim']);"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "ax = plt.subplot()\n",
        "plt.figure()\n",
        "sns.heatmap(confusion_matrix(Yd_test, Modelo5), annot=True, fmt=\".0f\", ax=ax, )\n",
        "\n",
        "ax.set_xlabel('Predicted labels');ax.set_ylabel('True labels'); \n",
        "ax.set_title('Arvore de Classificação'); \n",
        "ax.xaxis.set_ticklabels(['Bom', 'Ruim']); ax.yaxis.set_ticklabels(['Bom', 'Ruim']);"
      ],
      "metadata": {
        "id": "5sbOuqpMViW6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "ax = plt.subplot()\n",
        "plt.figure()\n",
        "sns.heatmap(confusion_matrix(Yd_test, Modelo6), annot=True, fmt=\".0f\", ax=ax, )\n",
        "\n",
        "ax.set_xlabel('Predicted labels');ax.set_ylabel('True labels'); \n",
        "ax.set_title('Random Forest'); \n",
        "ax.xaxis.set_ticklabels(['Bom', 'Ruim']); ax.yaxis.set_ticklabels(['Bom', 'Ruim']);"
      ],
      "metadata": {
        "id": "LB-0QDcIDoTJ"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [],
      "provenance": [],
      "mount_file_id": "1qNHO-1LVxSewawgH_DZ0IbwXIVXEhkk8",
      "authorship_tag": "ABX9TyNgUszeNbR2v9wLMZz8dTIa",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}